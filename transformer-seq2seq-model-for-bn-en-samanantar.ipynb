{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c6ed23",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-02T17:57:56.358288Z",
     "iopub.status.busy": "2024-03-02T17:57:56.357533Z",
     "iopub.status.idle": "2024-03-02T17:57:57.165330Z",
     "shell.execute_reply": "2024-03-02T17:57:57.164210Z"
    },
    "papermill": {
     "duration": 0.821332,
     "end_time": "2024-03-02T17:57:57.168282",
     "exception": false,
     "start_time": "2024-03-02T17:57:56.346950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/samanantar/final_data/en-ta/train.ta\n",
      "/kaggle/input/samanantar/final_data/en-ta/train.en\n",
      "/kaggle/input/samanantar/final_data/en-ml/train.ml\n",
      "/kaggle/input/samanantar/final_data/en-ml/train.en\n",
      "/kaggle/input/samanantar/final_data/en-as/train.as\n",
      "/kaggle/input/samanantar/final_data/en-as/train.en\n",
      "/kaggle/input/samanantar/final_data/en-kn/train.kn\n",
      "/kaggle/input/samanantar/final_data/en-kn/train.en\n",
      "/kaggle/input/samanantar/final_data/en-pa/train.pa\n",
      "/kaggle/input/samanantar/final_data/en-pa/train.en\n",
      "/kaggle/input/samanantar/final_data/en-mr/train.mr\n",
      "/kaggle/input/samanantar/final_data/en-mr/train.en\n",
      "/kaggle/input/samanantar/final_data/en-hi/train.hi\n",
      "/kaggle/input/samanantar/final_data/en-hi/train.en\n",
      "/kaggle/input/samanantar/final_data/en-bn/train.bn\n",
      "/kaggle/input/samanantar/final_data/en-bn/train.en\n",
      "/kaggle/input/samanantar/final_data/en-te/train.te\n",
      "/kaggle/input/samanantar/final_data/en-te/train.en\n",
      "/kaggle/input/samanantar/final_data/en-or/train.or\n",
      "/kaggle/input/samanantar/final_data/en-or/train.en\n",
      "/kaggle/input/samanantar/final_data/en-gu/train.gu\n",
      "/kaggle/input/samanantar/final_data/en-gu/train.en\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4d27e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:57:57.190257Z",
     "iopub.status.busy": "2024-03-02T17:57:57.189461Z",
     "iopub.status.idle": "2024-03-02T17:58:01.980537Z",
     "shell.execute_reply": "2024-03-02T17:58:01.979382Z"
    },
    "papermill": {
     "duration": 4.805044,
     "end_time": "2024-03-02T17:58:01.983725",
     "exception": false,
     "start_time": "2024-03-02T17:57:57.178681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from torch.utils.data import Dataset\n",
    "# import gc\n",
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'bn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747f6ea",
   "metadata": {
    "papermill": {
     "duration": 0.010884,
     "end_time": "2024-03-02T17:58:02.006627",
     "exception": false,
     "start_time": "2024-03-02T17:58:01.995743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae82c12a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:02.027681Z",
     "iopub.status.busy": "2024-03-02T17:58:02.027185Z",
     "iopub.status.idle": "2024-03-02T17:58:15.080062Z",
     "shell.execute_reply": "2024-03-02T17:58:15.078990Z"
    },
    "papermill": {
     "duration": 13.064866,
     "end_time": "2024-03-02T17:58:15.082624",
     "exception": false,
     "start_time": "2024-03-02T17:58:02.017758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f06efeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:15.102127Z",
     "iopub.status.busy": "2024-03-02T17:58:15.101799Z",
     "iopub.status.idle": "2024-03-02T17:58:31.547796Z",
     "shell.execute_reply": "2024-03-02T17:58:31.546569Z"
    },
    "papermill": {
     "duration": 16.458197,
     "end_time": "2024-03-02T17:58:31.549978",
     "exception": false,
     "start_time": "2024-03-02T17:58:15.091781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bnlp_toolkit\r\n",
      "  Downloading bnlp_toolkit-4.0.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from bnlp_toolkit) (0.2.0)\r\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (from bnlp_toolkit) (4.3.2)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from bnlp_toolkit) (3.2.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bnlp_toolkit) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bnlp_toolkit) (1.11.4)\r\n",
      "Collecting sklearn-crfsuite (from bnlp_toolkit)\r\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from bnlp_toolkit) (4.66.1)\r\n",
      "Collecting ftfy (from bnlp_toolkit)\r\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Collecting emoji==1.7.0 (from bnlp_toolkit)\r\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bnlp_toolkit) (2.31.0)\r\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->bnlp_toolkit) (0.2.13)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim->bnlp_toolkit) (6.4.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->bnlp_toolkit) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bnlp_toolkit) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bnlp_toolkit) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bnlp_toolkit) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bnlp_toolkit) (2024.2.2)\r\n",
      "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->bnlp_toolkit)\r\n",
      "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.0)\r\n",
      "Downloading bnlp_toolkit-4.0.0-py3-none-any.whl (22 kB)\r\n",
      "Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\r\n",
      "Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\r\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=6ee12c5afe091081c9561ac67be5842ea4ab34fda0a0347f6c3f22b4860158cd\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\r\n",
      "Successfully built emoji\r\n",
      "Installing collected packages: python-crfsuite, emoji, sklearn-crfsuite, ftfy, bnlp_toolkit\r\n",
      "  Attempting uninstall: emoji\r\n",
      "    Found existing installation: emoji 2.10.1\r\n",
      "    Uninstalling emoji-2.10.1:\r\n",
      "      Successfully uninstalled emoji-2.10.1\r\n",
      "Successfully installed bnlp_toolkit-4.0.0 emoji-1.7.0 ftfy-6.1.3 python-crfsuite-0.9.10 sklearn-crfsuite-0.3.6\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bnlp_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbad4206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:31.573657Z",
     "iopub.status.busy": "2024-03-02T17:58:31.573309Z",
     "iopub.status.idle": "2024-03-02T17:58:48.959988Z",
     "shell.execute_reply": "2024-03-02T17:58:48.959172Z"
    },
    "papermill": {
     "duration": 17.400935,
     "end_time": "2024-03-02T17:58:48.962340",
     "exception": false,
     "start_time": "2024-03-02T17:58:31.561405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bnlp import NLTKTokenizer\n",
    "\n",
    "bnltk = NLTKTokenizer()\n",
    "text = \"আমি ভাত খাই। সে বাজারে যায়। তিনি কি সত্যিই ভালো মানুষ?\"\n",
    "word_tokens = bnltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fa288b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:48.986836Z",
     "iopub.status.busy": "2024-03-02T17:58:48.986303Z",
     "iopub.status.idle": "2024-03-02T17:58:48.990993Z",
     "shell.execute_reply": "2024-03-02T17:58:48.990136Z"
    },
    "papermill": {
     "duration": 0.018502,
     "end_time": "2024-03-02T17:58:48.993167",
     "exception": false,
     "start_time": "2024-03-02T17:58:48.974665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['আমি', 'ভাত', 'খাই', '।', 'সে', 'বাজারে', 'যায়', '।', 'তিনি', 'কি', 'সত্যিই', 'ভালো', 'মানুষ', '?']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2efc2d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:49.016081Z",
     "iopub.status.busy": "2024-03-02T17:58:49.015805Z",
     "iopub.status.idle": "2024-03-02T17:58:49.019228Z",
     "shell.execute_reply": "2024-03-02T17:58:49.018418Z"
    },
    "papermill": {
     "duration": 0.01687,
     "end_time": "2024-03-02T17:58:49.021113",
     "exception": false,
     "start_time": "2024-03-02T17:58:49.004243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def tokenize(text):\n",
    "#     return bnltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c7c53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:49.043841Z",
     "iopub.status.busy": "2024-03-02T17:58:49.043573Z",
     "iopub.status.idle": "2024-03-02T17:58:54.158487Z",
     "shell.execute_reply": "2024-03-02T17:58:54.157569Z"
    },
    "papermill": {
     "duration": 5.128665,
     "end_time": "2024-03-02T17:58:54.160567",
     "exception": false,
     "start_time": "2024-03-02T17:58:49.031902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59ee10e565e4a8381ab27d6f5e02a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a33d04892ff47f6bd50f209a1b42496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['আমি', 'ভাল', '##ে', '##া', 'বাংলা', '##য', 'গান', 'গাই', '।']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "bnbert_tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "text = \"আমি ভালো বাংলায় গান গাই।\"\n",
    "bnbert_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140314a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:54.186394Z",
     "iopub.status.busy": "2024-03-02T17:58:54.185303Z",
     "iopub.status.idle": "2024-03-02T17:58:54.190938Z",
     "shell.execute_reply": "2024-03-02T17:58:54.190078Z"
    },
    "papermill": {
     "duration": 0.020236,
     "end_time": "2024-03-02T17:58:54.192938",
     "exception": false,
     "start_time": "2024-03-02T17:58:54.172702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return bnbert_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459ea774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:54.217433Z",
     "iopub.status.busy": "2024-03-02T17:58:54.217078Z",
     "iopub.status.idle": "2024-03-02T17:58:54.221983Z",
     "shell.execute_reply": "2024-03-02T17:58:54.220978Z"
    },
    "papermill": {
     "duration": 0.019784,
     "end_time": "2024-03-02T17:58:54.224109",
     "exception": false,
     "start_time": "2024-03-02T17:58:54.204325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b432cd27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:54.250170Z",
     "iopub.status.busy": "2024-03-02T17:58:54.249859Z",
     "iopub.status.idle": "2024-03-02T17:58:54.258647Z",
     "shell.execute_reply": "2024-03-02T17:58:54.257710Z"
    },
    "papermill": {
     "duration": 0.024741,
     "end_time": "2024-03-02T17:58:54.260688",
     "exception": false,
     "start_time": "2024-03-02T17:58:54.235947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_src='../input/samanantar/final_data/en-bn/train.en'\n",
    "dataset_tgt='../input/samanantar/final_data/en-bn/train.bn'\n",
    "class CustomizedSamanantar(Dataset):\n",
    "    def __init__(self, dataset_dir,tgt_dir,split=\"train\"):\n",
    "        with open(dataset_dir,\"r\") as f:\n",
    "            self.dataset=f.readlines()\n",
    "        with open(tgt_dir,\"r\") as f:\n",
    "            self.labels=f.readlines()\n",
    "        if split==\"train\":\n",
    "            self.dataset=self.dataset[:35000]\n",
    "            self.labels=self.labels[:35000]\n",
    "        if split==\"valid\":\n",
    "            self.dataset=self.dataset[30000:31000]\n",
    "            self.labels=self.labels[30000:31000]\n",
    "        if split==\"test\":\n",
    "            self.dataset=self.dataset[50000:]\n",
    "            self.labels=self.labels[50000:]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.dataset[idx],self.labels[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c287d803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:58:54.287262Z",
     "iopub.status.busy": "2024-03-02T17:58:54.286948Z",
     "iopub.status.idle": "2024-03-02T17:59:15.201796Z",
     "shell.execute_reply": "2024-03-02T17:59:15.200846Z"
    },
    "papermill": {
     "duration": 20.931627,
     "end_time": "2024-03-02T17:59:15.204182",
     "exception": false,
     "start_time": "2024-03-02T17:58:54.272555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a1da54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:59:15.232313Z",
     "iopub.status.busy": "2024-03-02T17:59:15.232003Z",
     "iopub.status.idle": "2024-03-02T17:59:55.486996Z",
     "shell.execute_reply": "2024-03-02T17:59:55.486160Z"
    },
    "papermill": {
     "duration": 40.271631,
     "end_time": "2024-03-02T17:59:55.489333",
     "exception": false,
     "start_time": "2024-03-02T17:59:15.217702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_iter = CustomizedSamanantar(dataset_src,dataset_tgt,split=\"train\")\n",
    "val_iter = CustomizedSamanantar(dataset_src,dataset_tgt,split=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8737d197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T17:59:55.517409Z",
     "iopub.status.busy": "2024-03-02T17:59:55.517116Z",
     "iopub.status.idle": "2024-03-02T18:00:08.402255Z",
     "shell.execute_reply": "2024-03-02T18:00:08.401463Z"
    },
    "papermill": {
     "duration": 12.901676,
     "end_time": "2024-03-02T18:00:08.404758",
     "exception": false,
     "start_time": "2024-03-02T17:59:55.503082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_transform={}\n",
    "vocab_transform = {}\n",
    "\n",
    "token_transform[TGT_LANGUAGE]=tokenize\n",
    "token_transform[SRC_LANGUAGE]=get_tokenizer('spacy',language='en_core_web_sm')\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "# train_iter=CustomizedSamanantar(dataset_src,dataset_tgt)\n",
    "for ln in [SRC_LANGUAGE,TGT_LANGUAGE]:\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                        min_freq=1,\n",
    "                                                        specials=special_symbols,\n",
    "                                                        special_first=True)\n",
    "\n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efe1bfe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:08.433384Z",
     "iopub.status.busy": "2024-03-02T18:00:08.432236Z",
     "iopub.status.idle": "2024-03-02T18:00:08.451777Z",
     "shell.execute_reply": "2024-03-02T18:00:08.450228Z"
    },
    "papermill": {
     "duration": 0.035846,
     "end_time": "2024-03-02T18:00:08.453902",
     "exception": false,
     "start_time": "2024-03-02T18:00:08.418056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network \n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, \n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a67ebb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:08.481331Z",
     "iopub.status.busy": "2024-03-02T18:00:08.481016Z",
     "iopub.status.idle": "2024-03-02T18:00:08.487983Z",
     "shell.execute_reply": "2024-03-02T18:00:08.487150Z"
    },
    "papermill": {
     "duration": 0.022819,
     "end_time": "2024-03-02T18:00:08.489860",
     "exception": false,
     "start_time": "2024-03-02T18:00:08.467041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e751d742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:08.517100Z",
     "iopub.status.busy": "2024-03-02T18:00:08.516400Z",
     "iopub.status.idle": "2024-03-02T18:00:10.193455Z",
     "shell.execute_reply": "2024-03-02T18:00:10.192634Z"
    },
    "papermill": {
     "duration": 1.693172,
     "end_time": "2024-03-02T18:00:10.195911",
     "exception": false,
     "start_time": "2024-03-02T18:00:08.502739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 20\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, \n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ba56dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:10.223784Z",
     "iopub.status.busy": "2024-03-02T18:00:10.223456Z",
     "iopub.status.idle": "2024-03-02T18:00:10.228304Z",
     "shell.execute_reply": "2024-03-02T18:00:10.227399Z"
    },
    "papermill": {
     "duration": 0.021131,
     "end_time": "2024-03-02T18:00:10.230445",
     "exception": false,
     "start_time": "2024-03-02T18:00:10.209314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36307 15112\n"
     ]
    }
   ],
   "source": [
    "print(SRC_VOCAB_SIZE,TGT_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1e1f392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:10.258428Z",
     "iopub.status.busy": "2024-03-02T18:00:10.257767Z",
     "iopub.status.idle": "2024-03-02T18:00:10.266910Z",
     "shell.execute_reply": "2024-03-02T18:00:10.266032Z"
    },
    "papermill": {
     "duration": 0.025364,
     "end_time": "2024-03-02T18:00:10.268934",
     "exception": false,
     "start_time": "2024-03-02T18:00:10.243570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22f7f0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:10.295455Z",
     "iopub.status.busy": "2024-03-02T18:00:10.295176Z",
     "iopub.status.idle": "2024-03-02T18:00:10.305917Z",
     "shell.execute_reply": "2024-03-02T18:00:10.305221Z"
    },
    "papermill": {
     "duration": 0.026133,
     "end_time": "2024-03-02T18:00:10.307875",
     "exception": false,
     "start_time": "2024-03-02T18:00:10.281742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    \n",
    "    for src, tgt in train_dataloader:\n",
    "#         print(len(src),len(tgt),src,tgt)\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(train_dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        \n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a87a53d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:10.334315Z",
     "iopub.status.busy": "2024-03-02T18:00:10.334051Z",
     "iopub.status.idle": "2024-03-02T18:00:18.909812Z",
     "shell.execute_reply": "2024-03-02T18:00:18.908900Z"
    },
    "papermill": {
     "duration": 8.591194,
     "end_time": "2024-03-02T18:00:18.911925",
     "exception": false,
     "start_time": "2024-03-02T18:00:10.320731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n"
     ]
    }
   ],
   "source": [
    "dataset=CustomizedSamanantar(dataset_src,dataset_tgt)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "373ba3e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:18.939651Z",
     "iopub.status.busy": "2024-03-02T18:00:18.939320Z",
     "iopub.status.idle": "2024-03-02T18:00:18.944186Z",
     "shell.execute_reply": "2024-03-02T18:00:18.943084Z"
    },
    "papermill": {
     "duration": 0.020721,
     "end_time": "2024-03-02T18:00:18.946171",
     "exception": false,
     "start_time": "2024-03-02T18:00:18.925450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('However, he did not give further details.\\n', 'তবে এর চেয়ে বেশি তথ্য তিনি দেননি।\\n')\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20cb8eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:18.973138Z",
     "iopub.status.busy": "2024-03-02T18:00:18.972871Z",
     "iopub.status.idle": "2024-03-02T18:00:18.983383Z",
     "shell.execute_reply": "2024-03-02T18:00:18.982556Z"
    },
    "papermill": {
     "duration": 0.026325,
     "end_time": "2024-03-02T18:00:18.985324",
     "exception": false,
     "start_time": "2024-03-02T18:00:18.958999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm \n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "042027bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:19.011933Z",
     "iopub.status.busy": "2024-03-02T18:00:19.011696Z",
     "iopub.status.idle": "2024-03-02T18:00:19.015204Z",
     "shell.execute_reply": "2024-03-02T18:00:19.014380Z"
    },
    "papermill": {
     "duration": 0.019074,
     "end_time": "2024-03-02T18:00:19.017137",
     "exception": false,
     "start_time": "2024-03-02T18:00:18.998063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_iter = CustomizedSamanantar(dataset_src,dataset_tgt,split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c22a7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:19.043592Z",
     "iopub.status.busy": "2024-03-02T18:00:19.043292Z",
     "iopub.status.idle": "2024-03-02T18:00:19.048455Z",
     "shell.execute_reply": "2024-03-02T18:00:19.047746Z"
    },
    "papermill": {
     "duration": 0.020342,
     "end_time": "2024-03-02T18:00:19.050202",
     "exception": false,
     "start_time": "2024-03-02T18:00:19.029860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "try:\n",
    "    with open('filename.pkl', 'rb') as f:\n",
    "        transformer = pickle.load(f)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12951261",
   "metadata": {
    "papermill": {
     "duration": 0.012482,
     "end_time": "2024-03-02T18:00:19.075639",
     "exception": false,
     "start_time": "2024-03-02T18:00:19.063157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "715817d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T18:00:19.103290Z",
     "iopub.status.busy": "2024-03-02T18:00:19.102557Z",
     "iopub.status.idle": "2024-03-03T00:36:41.796570Z",
     "shell.execute_reply": "2024-03-03T00:36:41.795616Z"
    },
    "papermill": {
     "duration": 23782.742894,
     "end_time": "2024-03-03T00:36:41.831286",
     "exception": false,
     "start_time": "2024-03-02T18:00:19.088392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 5.800 | Train PPL: 330.316\n",
      "\t Val. Loss: 4.828 |  Val. PPL: 124.955\n",
      " কিনত কিনত কে ##ান ##ও কি ##ছ ##ই না । \n",
      "Epoch  1 Duration =  95.40065773700002\n",
      "\tTrain Loss: 4.791 | Train PPL: 120.364\n",
      "\t Val. Loss: 4.332 |  Val. PPL:  76.087\n",
      " কে ##ান ##ও কে ##ান ##ও নেই । \n",
      "Epoch  2 Duration =  94.56078994999996\n",
      "\tTrain Loss: 4.419 | Train PPL:  83.031\n",
      "\t Val. Loss: 3.996 |  Val. PPL:  54.360\n",
      " কে ##ান ##ও কে ##ান ##ও নেই । \n",
      "Epoch  3 Duration =  94.61288079199994\n",
      "\tTrain Loss: 4.151 | Train PPL:  63.490\n",
      "\t Val. Loss: 3.747 |  Val. PPL:  42.407\n",
      " কে ##ান ##ও কে ##ান ##ও কে ##ান ##ও কে ##ান ##ও\n",
      "Epoch  4 Duration =  94.51492918500003\n",
      "\tTrain Loss: 3.931 | Train PPL:  50.955\n",
      "\t Val. Loss: 3.514 |  Val. PPL:  33.592\n",
      " কে ##ান ##ও কষ ##তি নেই । \n",
      "Epoch  5 Duration =  94.55338160400004\n",
      "\tTrain Loss: 3.739 | Train PPL:  42.066\n",
      "\t Val. Loss: 3.294 |  Val. PPL:  26.962\n",
      " কে ##ান ##ও কষ ##তি নেই । \n",
      "Epoch  6 Duration =  94.610696394\n",
      "\tTrain Loss: 3.563 | Train PPL:  35.277\n",
      "\t Val. Loss: 3.112 |  Val. PPL:  22.468\n",
      " কে ##ান ##ও কষ ##তি নেই । \n",
      "Epoch  7 Duration =  94.5237421270001\n",
      "\tTrain Loss: 3.399 | Train PPL:  29.942\n",
      "\t Val. Loss: 2.934 |  Val. PPL:  18.806\n",
      " কে ##ান ##ও কষ ##তি হবে না । \n",
      "Epoch  8 Duration =  94.64787498499993\n",
      "\tTrain Loss: 3.243 | Train PPL:  25.599\n",
      "\t Val. Loss: 2.755 |  Val. PPL:  15.720\n",
      " কে ##ান ##ও কষ ##তি হবে না । \n",
      "Epoch  9 Duration =  94.4312805940001\n",
      "\tTrain Loss: 3.093 | Train PPL:  22.032\n",
      "\t Val. Loss: 2.589 |  Val. PPL:  13.310\n",
      " সেখানে আর কে ##ান ##ও কষ ##তি হবে না । \n",
      "Epoch  10 Duration =  94.3843734479999\n",
      "\tTrain Loss: 2.948 | Train PPL:  19.066\n",
      "\t Val. Loss: 2.422 |  Val. PPL:  11.272\n",
      " ও ##র মধ ##যে কে ##ান ##ও স ##যে ##াগ নেই ।\n",
      "Epoch  11 Duration =  94.42992323499993\n",
      "\tTrain Loss: 2.809 | Train PPL:  16.601\n",
      "\t Val. Loss: 2.272 |  Val. PPL:   9.701\n",
      " ও ##যে ##ব ##যব ##স ##থা করা হবে না । \n",
      "Epoch  12 Duration =  94.59345390299995\n",
      "\tTrain Loss: 2.680 | Train PPL:  14.591\n",
      "\t Val. Loss: 2.075 |  Val. PPL:   7.963\n",
      " ও ##যে ##ব ##ডে দেও ##যা হবে না । \n",
      "Epoch  13 Duration =  94.39466397699994\n",
      "\tTrain Loss: 2.554 | Train PPL:  12.860\n",
      "\t Val. Loss: 1.933 |  Val. PPL:   6.907\n",
      " ও ##র মধ ##যে কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  14 Duration =  94.35968704600009\n",
      "\tTrain Loss: 2.430 | Train PPL:  11.357\n",
      "\t Val. Loss: 1.781 |  Val. PPL:   5.939\n",
      " ও ##যে ##ব চ ##ডান ##ত হবে না । \n",
      "Epoch  15 Duration =  94.48520863499994\n",
      "\tTrain Loss: 2.314 | Train PPL:  10.119\n",
      "\t Val. Loss: 1.637 |  Val. PPL:   5.142\n",
      " ও ##র ফল হবে না । \n",
      "Epoch  16 Duration =  94.39539703200012\n",
      "\tTrain Loss: 2.204 | Train PPL:   9.058\n",
      "\t Val. Loss: 1.528 |  Val. PPL:   4.608\n",
      " ও ##যে ##ব ##যব ##স ##থা করা হবে না । \n",
      "Epoch  17 Duration =  94.35490527599995\n",
      "\tTrain Loss: 2.097 | Train PPL:   8.144\n",
      "\t Val. Loss: 1.414 |  Val. PPL:   4.111\n",
      " ও ##যে ##ব সিরিজে তে ##া করা হবে না । \n",
      "Epoch  18 Duration =  94.36195481499976\n",
      "\tTrain Loss: 1.998 | Train PPL:   7.374\n",
      "\t Val. Loss: 1.312 |  Val. PPL:   3.713\n",
      " ও ##যে ##ব ##যব ##হার করা হবে না । \n",
      "Epoch  19 Duration =  94.35780059799981\n",
      "\tTrain Loss: 1.903 | Train PPL:   6.708\n",
      "\t Val. Loss: 1.203 |  Val. PPL:   3.332\n",
      " ও ##যে ##ব ##যথা হবে না । \n",
      "Epoch  20 Duration =  94.48351401800028\n",
      "\tTrain Loss: 1.814 | Train PPL:   6.134\n",
      "\t Val. Loss: 1.089 |  Val. PPL:   2.971\n",
      " ও ##কে চ ##ডান ##ত হবে না । \n",
      "Epoch  21 Duration =  94.58657835199983\n",
      "\tTrain Loss: 1.729 | Train PPL:   5.637\n",
      "\t Val. Loss: 1.012 |  Val. PPL:   2.751\n",
      " ও ##যে ##বসা ##ইট ##ে ভে ##াট হবে না । \n",
      "Epoch  22 Duration =  94.46617319699999\n",
      "\tTrain Loss: 1.651 | Train PPL:   5.210\n",
      "\t Val. Loss: 0.949 |  Val. PPL:   2.583\n",
      " ও ##যে ##বসা ##ইট ##ে দে ##যা হবে না । \n",
      "Epoch  23 Duration =  94.65054192299976\n",
      "\tTrain Loss: 1.574 | Train PPL:   4.826\n",
      "\t Val. Loss: 0.899 |  Val. PPL:   2.458\n",
      " এতে করে পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  24 Duration =  95.29039943299995\n",
      "\tTrain Loss: 1.502 | Train PPL:   4.493\n",
      "\t Val. Loss: 0.805 |  Val. PPL:   2.237\n",
      " ও ##যে ##বসা ##ইট ছিল না । \n",
      "Epoch  25 Duration =  94.2880766610001\n",
      "\tTrain Loss: 1.434 | Train PPL:   4.198\n",
      "\t Val. Loss: 0.737 |  Val. PPL:   2.090\n",
      " ও ##যে ##বসা ##ইট ##ে করে নেও ##যা হবে না । \n",
      "Epoch  26 Duration =  94.26836295799967\n",
      "\tTrain Loss: 1.371 | Train PPL:   3.939\n",
      "\t Val. Loss: 0.680 |  Val. PPL:   1.973\n",
      " এবং পরে ##কষ ##িতে হস ##তান ##তর করে নিতে হবে না ।\n",
      "Epoch  27 Duration =  94.29537849099961\n",
      "\tTrain Loss: 1.311 | Train PPL:   3.709\n",
      "\t Val. Loss: 0.624 |  Val. PPL:   1.866\n",
      " করে কাজ করবে এবং পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  28 Duration =  94.67225183699975\n",
      "\tTrain Loss: 1.255 | Train PPL:   3.509\n",
      "\t Val. Loss: 0.590 |  Val. PPL:   1.804\n",
      " করে কাজ করবে না । \n",
      "Epoch  29 Duration =  94.82946896000021\n",
      "\tTrain Loss: 1.204 | Train PPL:   3.333\n",
      "\t Val. Loss: 0.544 |  Val. PPL:   1.723\n",
      " করে কাজ ##কর ##মে করে না । \n",
      "Epoch  30 Duration =  95.41346218099989\n",
      "\tTrain Loss: 1.155 | Train PPL:   3.173\n",
      "\t Val. Loss: 0.518 |  Val. PPL:   1.678\n",
      " এবং চ ##ডান ##ত সিদ ##ধান ##ত নেও ##যা হবে না ।\n",
      "Epoch  31 Duration =  94.75929980299998\n",
      "\tTrain Loss: 1.113 | Train PPL:   3.043\n",
      "\t Val. Loss: 0.485 |  Val. PPL:   1.625\n",
      " এবং করে কাজ হবে না । \n",
      "Epoch  32 Duration =  95.03503649999993\n",
      "\tTrain Loss: 1.072 | Train PPL:   2.922\n",
      "\t Val. Loss: 0.460 |  Val. PPL:   1.584\n",
      " এবং পর ##যে ##াজ ##নে ##েল ম ##যা ##চ করা হবে না\n",
      "Epoch  33 Duration =  94.96412398599978\n",
      "\tTrain Loss: 1.034 | Train PPL:   2.813\n",
      "\t Val. Loss: 0.445 |  Val. PPL:   1.560\n",
      " করে ##েল আহমেদ এবং ##ান ##তর ##থ হও ##যা উচিত নয ।\n",
      "Epoch  34 Duration =  95.4380329569999\n",
      "\tTrain Loss: 1.002 | Train PPL:   2.724\n",
      "\t Val. Loss: 0.414 |  Val. PPL:   1.514\n",
      " এবং করে কাজ ##কর ##মে ছবির কে ##ান ##ও দরকার নেই ।\n",
      "Epoch  35 Duration =  95.35451243099988\n",
      "\tTrain Loss: 0.970 | Train PPL:   2.637\n",
      "\t Val. Loss: 0.400 |  Val. PPL:   1.491\n",
      " এবং করত ##ক আয ##কর ##মী হও ##যা উচিত নয । \n",
      "Epoch  36 Duration =  95.20701948299984\n",
      "\tTrain Loss: 0.943 | Train PPL:   2.569\n",
      "\t Val. Loss: 0.388 |  Val. PPL:   1.475\n",
      " ও ##যা ##শিং ##টন করে ফেলে দেও ##যা হবে না । \n",
      "Epoch  37 Duration =  95.21531533899997\n",
      "\tTrain Loss: 0.920 | Train PPL:   2.509\n",
      "\t Val. Loss: 0.376 |  Val. PPL:   1.457\n",
      " এবং করত ##ক পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  38 Duration =  94.318230244\n",
      "\tTrain Loss: 0.902 | Train PPL:   2.463\n",
      "\t Val. Loss: 0.364 |  Val. PPL:   1.439\n",
      " এবং উপ ##স ##থি ##ত থাকবেন না । \n",
      "Epoch  39 Duration =  94.2894229819999\n",
      "\tTrain Loss: 0.885 | Train PPL:   2.424\n",
      "\t Val. Loss: 0.364 |  Val. PPL:   1.439\n",
      " এবং নিরব ##িকার থাকতে হবে না । \n",
      "Epoch  40 Duration =  94.20561929700034\n",
      "\tTrain Loss: 0.871 | Train PPL:   2.389\n",
      "\t Val. Loss: 0.359 |  Val. PPL:   1.432\n",
      " এবং পর ##যে ##াজ ##ন করে নেও ##যা হবে না । \n",
      "Epoch  41 Duration =  94.34276920100001\n",
      "\tTrain Loss: 0.851 | Train PPL:   2.341\n",
      "\t Val. Loss: 0.361 |  Val. PPL:   1.435\n",
      " এবং করত ##ক পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  42 Duration =  94.55817161800042\n",
      "\tTrain Loss: 0.831 | Train PPL:   2.296\n",
      "\t Val. Loss: 0.357 |  Val. PPL:   1.429\n",
      " এবং পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  43 Duration =  95.17089097799999\n",
      "\tTrain Loss: 0.811 | Train PPL:   2.251\n",
      "\t Val. Loss: 0.343 |  Val. PPL:   1.409\n",
      " এবং নিরব ##াচ ##ন করে নেও ##যা হবে না । \n",
      "Epoch  44 Duration =  94.28323675699994\n",
      "\tTrain Loss: 0.793 | Train PPL:   2.210\n",
      "\t Val. Loss: 0.331 |  Val. PPL:   1.392\n",
      " এবং পর ##যে ##াজ ##ন করে দেবে না । \n",
      "Epoch  45 Duration =  94.32939630700002\n",
      "\tTrain Loss: 0.775 | Train PPL:   2.170\n",
      "\t Val. Loss: 0.328 |  Val. PPL:   1.388\n",
      " এবং পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  46 Duration =  94.25940764100051\n",
      "\tTrain Loss: 0.758 | Train PPL:   2.134\n",
      "\t Val. Loss: 0.314 |  Val. PPL:   1.369\n",
      " এবং পর ##যে ##াজ ##ক হবে না । \n",
      "Epoch  47 Duration =  94.25979340100002\n",
      "\tTrain Loss: 0.738 | Train PPL:   2.093\n",
      "\t Val. Loss: 0.299 |  Val. PPL:   1.348\n",
      " এবং পর ##যে ##াজ ##নে কে ##ান ##ও কাজ হবে না ।\n",
      "Epoch  48 Duration =  94.67379621100008\n",
      "\tTrain Loss: 0.722 | Train PPL:   2.059\n",
      "\t Val. Loss: 0.294 |  Val. PPL:   1.341\n",
      " পর ##যে ##াজ ##নে কেউ ভাল ##ে ##া হবে না । \n",
      "Epoch  49 Duration =  95.50603875899924\n",
      "\tTrain Loss: 0.705 | Train PPL:   2.024\n",
      "\t Val. Loss: 0.289 |  Val. PPL:   1.335\n",
      " পর ##যে ##াজ ##নে দ ##টি ##যা পাচ ##ছে না । \n",
      "Epoch  50 Duration =  95.22213479600032\n",
      "\tTrain Loss: 0.688 | Train PPL:   1.990\n",
      "\t Val. Loss: 0.278 |  Val. PPL:   1.321\n",
      " পর ##যে ##াজ ##নে এরা দল হবে না । \n",
      "Epoch  51 Duration =  94.3432665499995\n",
      "\tTrain Loss: 0.673 | Train PPL:   1.960\n",
      "\t Val. Loss: 0.267 |  Val. PPL:   1.307\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  52 Duration =  94.29895885599944\n",
      "\tTrain Loss: 0.659 | Train PPL:   1.933\n",
      "\t Val. Loss: 0.262 |  Val. PPL:   1.299\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  53 Duration =  94.27347244700013\n",
      "\tTrain Loss: 0.647 | Train PPL:   1.910\n",
      "\t Val. Loss: 0.254 |  Val. PPL:   1.289\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  54 Duration =  94.40302104300008\n",
      "\tTrain Loss: 0.638 | Train PPL:   1.892\n",
      "\t Val. Loss: 0.253 |  Val. PPL:   1.288\n",
      " এবং পর ##যে ##াজ ##ন করে দেও ##যা হবে না । \n",
      "Epoch  55 Duration =  94.28056339999966\n",
      "\tTrain Loss: 0.629 | Train PPL:   1.875\n",
      "\t Val. Loss: 0.253 |  Val. PPL:   1.288\n",
      " পর ##যে ##াজ ##নে দ ##টি করে দেও ##যা হবে না ।\n",
      "Epoch  56 Duration =  94.27443779100031\n",
      "\tTrain Loss: 0.616 | Train PPL:   1.852\n",
      "\t Val. Loss: 0.245 |  Val. PPL:   1.278\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  57 Duration =  94.30108491699957\n",
      "\tTrain Loss: 0.605 | Train PPL:   1.831\n",
      "\t Val. Loss: 0.244 |  Val. PPL:   1.277\n",
      " পর ##যে ##াজ ##নে এরা দল হবে না । \n",
      "Epoch  58 Duration =  94.31015008099985\n",
      "\tTrain Loss: 0.595 | Train PPL:   1.813\n",
      "\t Val. Loss: 0.231 |  Val. PPL:   1.260\n",
      " পর ##যে ##াজ ##নে দ ##টি করে দেও ##যা হবে না ।\n",
      "Epoch  59 Duration =  94.30630811899937\n",
      "\tTrain Loss: 0.588 | Train PPL:   1.801\n",
      "\t Val. Loss: 0.229 |  Val. PPL:   1.257\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও সার ##টি হবে না ।\n",
      "Epoch  60 Duration =  94.37278577100005\n",
      "\tTrain Loss: 0.576 | Train PPL:   1.779\n",
      "\t Val. Loss: 0.226 |  Val. PPL:   1.253\n",
      " ৩ করে কাজ হবে না । \n",
      "Epoch  61 Duration =  94.46694608800044\n",
      "\tTrain Loss: 0.569 | Train PPL:   1.766\n",
      "\t Val. Loss: 0.230 |  Val. PPL:   1.259\n",
      " এবং পর ##যে ##াজ ##নে দ ##ধ হবেন না । \n",
      "Epoch  62 Duration =  94.2738114169997\n",
      "\tTrain Loss: 0.560 | Train PPL:   1.750\n",
      "\t Val. Loss: 0.230 |  Val. PPL:   1.258\n",
      " ৩ . কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  63 Duration =  95.06199936299981\n",
      "\tTrain Loss: 0.550 | Train PPL:   1.734\n",
      "\t Val. Loss: 0.225 |  Val. PPL:   1.252\n",
      " পর ##যে ##াজ ##নে দ ##ষট ##ান ##ত হবে না । \n",
      "Epoch  64 Duration =  94.24702845899992\n",
      "\tTrain Loss: 0.545 | Train PPL:   1.724\n",
      "\t Val. Loss: 0.228 |  Val. PPL:   1.257\n",
      " এবং পর ##যে ##াজ ##নে ৩ : [UNK] ) হবে না ।\n",
      "Epoch  65 Duration =  94.31758501799959\n",
      "\tTrain Loss: 0.534 | Train PPL:   1.706\n",
      "\t Val. Loss: 0.221 |  Val. PPL:   1.247\n",
      " পর ##যে ##াজ ##নে দ ##ষট ##ান ##ত হবে না । \n",
      "Epoch  66 Duration =  94.27762885599986\n",
      "\tTrain Loss: 0.526 | Train PPL:   1.692\n",
      "\t Val. Loss: 0.219 |  Val. PPL:   1.245\n",
      " পর ##যে ##াজ ##নে দ ##টি করে দল দেও ##যা হবে না\n",
      "Epoch  67 Duration =  94.41359817500052\n",
      "\tTrain Loss: 0.518 | Train PPL:   1.679\n",
      "\t Val. Loss: 0.212 |  Val. PPL:   1.236\n",
      " এবং পর ##যে ##াজ ##ন কেউ করে দেও ##যা হবে না ।\n",
      "Epoch  68 Duration =  94.36773577199983\n",
      "\tTrain Loss: 0.510 | Train PPL:   1.665\n",
      "\t Val. Loss: 0.210 |  Val. PPL:   1.233\n",
      " এবং পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  69 Duration =  94.37847129900001\n",
      "\tTrain Loss: 0.504 | Train PPL:   1.656\n",
      "\t Val. Loss: 0.219 |  Val. PPL:   1.245\n",
      " পর ##যে ##াজ ##নে দ ##টি ম ##ঙ ##গল ##প নেই ।\n",
      "Epoch  70 Duration =  94.2213876019996\n",
      "\tTrain Loss: 0.500 | Train PPL:   1.648\n",
      "\t Val. Loss: 0.217 |  Val. PPL:   1.243\n",
      " পর ##যে ##াজ ##নে দ ##টি ম ##ঙ ##গল ##প নেই ।\n",
      "Epoch  71 Duration =  94.17192008599977\n",
      "\tTrain Loss: 0.496 | Train PPL:   1.642\n",
      "\t Val. Loss: 0.215 |  Val. PPL:   1.240\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  72 Duration =  94.23292147899974\n",
      "\tTrain Loss: 0.495 | Train PPL:   1.640\n",
      "\t Val. Loss: 0.223 |  Val. PPL:   1.250\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  73 Duration =  94.22132037200026\n",
      "\tTrain Loss: 0.490 | Train PPL:   1.633\n",
      "\t Val. Loss: 0.205 |  Val. PPL:   1.227\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  74 Duration =  94.33423108500028\n",
      "\tTrain Loss: 0.492 | Train PPL:   1.636\n",
      "\t Val. Loss: 0.213 |  Val. PPL:   1.237\n",
      " পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  75 Duration =  94.26115447399934\n",
      "\tTrain Loss: 0.491 | Train PPL:   1.634\n",
      "\t Val. Loss: 0.219 |  Val. PPL:   1.245\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  76 Duration =  94.13528513299934\n",
      "\tTrain Loss: 0.492 | Train PPL:   1.636\n",
      "\t Val. Loss: 0.217 |  Val. PPL:   1.242\n",
      " পর ##যে ##াজ ##নে মে ##াট ধরনের দল হবে না । \n",
      "Epoch  77 Duration =  94.09954635900067\n",
      "\tTrain Loss: 0.491 | Train PPL:   1.634\n",
      "\t Val. Loss: 0.225 |  Val. PPL:   1.252\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  78 Duration =  94.29329390200019\n",
      "\tTrain Loss: 0.490 | Train PPL:   1.632\n",
      "\t Val. Loss: 0.216 |  Val. PPL:   1.241\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও কাজ নেই । \n",
      "Epoch  79 Duration =  94.64259795999988\n",
      "\tTrain Loss: 0.487 | Train PPL:   1.628\n",
      "\t Val. Loss: 0.222 |  Val. PPL:   1.249\n",
      " এবং নিরব ##াচ ##ন করে বিকেল ৫ : [UNK] নেই । \n",
      "Epoch  80 Duration =  94.34634150800048\n",
      "\tTrain Loss: 0.484 | Train PPL:   1.623\n",
      "\t Val. Loss: 0.212 |  Val. PPL:   1.236\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  81 Duration =  94.43064813699948\n",
      "\tTrain Loss: 0.484 | Train PPL:   1.623\n",
      "\t Val. Loss: 0.215 |  Val. PPL:   1.240\n",
      " ৩ , [UNK] পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  82 Duration =  94.34009087300001\n",
      "\tTrain Loss: 0.482 | Train PPL:   1.619\n",
      "\t Val. Loss: 0.214 |  Val. PPL:   1.239\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  83 Duration =  94.24869024100008\n",
      "\tTrain Loss: 0.478 | Train PPL:   1.614\n",
      "\t Val. Loss: 0.219 |  Val. PPL:   1.245\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও নথি ##ভ ##কত করে না\n",
      "Epoch  84 Duration =  94.47043978500005\n",
      "\tTrain Loss: 0.476 | Train PPL:   1.610\n",
      "\t Val. Loss: 0.223 |  Val. PPL:   1.249\n",
      " পর ##যে ##াজ ##ন নেই , এই গর ##হণ ##ের । \n",
      "Epoch  85 Duration =  94.61105335200045\n",
      "\tTrain Loss: 0.473 | Train PPL:   1.605\n",
      "\t Val. Loss: 0.219 |  Val. PPL:   1.245\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  86 Duration =  94.36101734799922\n",
      "\tTrain Loss: 0.472 | Train PPL:   1.603\n",
      "\t Val. Loss: 0.221 |  Val. PPL:   1.248\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  87 Duration =  94.35256197599847\n",
      "\tTrain Loss: 0.471 | Train PPL:   1.602\n",
      "\t Val. Loss: 0.215 |  Val. PPL:   1.240\n",
      " পর ##যে ##াজ ##ন করে ওরা , এই ব ##যা ##পার ##টা\n",
      "Epoch  88 Duration =  94.25881727999877\n",
      "\tTrain Loss: 0.469 | Train PPL:   1.599\n",
      "\t Val. Loss: 0.221 |  Val. PPL:   1.247\n",
      " পর ##যে ##াজ ##ন করে আইনের আওতা ##য নেই । \n",
      "Epoch  89 Duration =  94.24785780599996\n",
      "\tTrain Loss: 0.466 | Train PPL:   1.593\n",
      "\t Val. Loss: 0.221 |  Val. PPL:   1.247\n",
      " পর ##যে ##াজ ##নী ##য নথি ##ভ ##কত করে না । \n",
      "Epoch  90 Duration =  94.3265057009994\n",
      "\tTrain Loss: 0.465 | Train PPL:   1.591\n",
      "\t Val. Loss: 0.222 |  Val. PPL:   1.249\n",
      " পর ##যে ##াজ ##ন করে কে ##ান ##ও কাজ হবে না ।\n",
      "Epoch  91 Duration =  94.26996252599929\n",
      "\tTrain Loss: 0.463 | Train PPL:   1.589\n",
      "\t Val. Loss: 0.226 |  Val. PPL:   1.253\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও দিকে ##প নেই । \n",
      "Epoch  92 Duration =  94.26073264200022\n",
      "\tTrain Loss: 0.460 | Train PPL:   1.584\n",
      "\t Val. Loss: 0.212 |  Val. PPL:   1.236\n",
      " পর ##যে ##াজ ##ন করে কে ##ান ##ও কাজ নেই । \n",
      "Epoch  93 Duration =  94.29492932100038\n",
      "\tTrain Loss: 0.458 | Train PPL:   1.580\n",
      "\t Val. Loss: 0.211 |  Val. PPL:   1.235\n",
      " ৩ ) পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  94 Duration =  94.30624301999887\n",
      "\tTrain Loss: 0.454 | Train PPL:   1.575\n",
      "\t Val. Loss: 0.218 |  Val. PPL:   1.243\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও পাচ ##ছে না । \n",
      "Epoch  95 Duration =  94.26272436900035\n",
      "\tTrain Loss: 0.452 | Train PPL:   1.572\n",
      "\t Val. Loss: 0.218 |  Val. PPL:   1.244\n",
      " ৩ ) পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  96 Duration =  94.17905335899923\n",
      "\tTrain Loss: 0.452 | Train PPL:   1.571\n",
      "\t Val. Loss: 0.218 |  Val. PPL:   1.243\n",
      " পর ##যে ##াজ ##ন করে কে ##ান ##ও পাচ ##ছে না ।\n",
      "Epoch  97 Duration =  94.18126429499898\n",
      "\tTrain Loss: 0.447 | Train PPL:   1.564\n",
      "\t Val. Loss: 0.210 |  Val. PPL:   1.234\n",
      " পর ##যে ##াজ ##নে কে ##ান ##ও অধিকার নেই । \n",
      "Epoch  98 Duration =  94.4247809239987\n",
      "\tTrain Loss: 0.443 | Train PPL:   1.558\n",
      "\t Val. Loss: 0.211 |  Val. PPL:   1.235\n",
      " পর ##যে ##াজ ##ন করে কে ##ান ##ও দিকে । \n",
      "Epoch  99 Duration =  94.34511467399898\n",
      "\tTrain Loss: 0.442 | Train PPL:   1.555\n",
      "\t Val. Loss: 0.211 |  Val. PPL:   1.235\n",
      " ৩ , [UNK] করে পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  100 Duration =  94.49040971899922\n",
      "\tTrain Loss: 0.441 | Train PPL:   1.554\n",
      "\t Val. Loss: 0.208 |  Val. PPL:   1.231\n",
      " এবং আপনাকে দশ ##য ##বে ##াধ করার দরকার নেই । \n",
      "Epoch  101 Duration =  94.19329221100088\n",
      "\tTrain Loss: 0.439 | Train PPL:   1.552\n",
      "\t Val. Loss: 0.205 |  Val. PPL:   1.228\n",
      " সেখানে উপ ##য ##কত করে জল পাবেন না । \n",
      "Epoch  102 Duration =  94.16753432000041\n",
      "\tTrain Loss: 0.437 | Train PPL:   1.547\n",
      "\t Val. Loss: 0.203 |  Val. PPL:   1.225\n",
      " ৩ ) [UNK] করে কে ##ান ##ও দিকে । \n",
      "Epoch  103 Duration =  94.2353770640002\n",
      "\tTrain Loss: 0.434 | Train PPL:   1.544\n",
      "\t Val. Loss: 0.203 |  Val. PPL:   1.225\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  104 Duration =  94.15385781300029\n",
      "\tTrain Loss: 0.434 | Train PPL:   1.543\n",
      "\t Val. Loss: 0.201 |  Val. PPL:   1.223\n",
      " [UNK] পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  105 Duration =  94.04616754500057\n",
      "\tTrain Loss: 0.429 | Train PPL:   1.535\n",
      "\t Val. Loss: 0.196 |  Val. PPL:   1.216\n",
      " পর ##যে ##াজ ##ন করে এরপর এই দিকে । \n",
      "Epoch  106 Duration =  94.1910410950004\n",
      "\tTrain Loss: 0.426 | Train PPL:   1.531\n",
      "\t Val. Loss: 0.201 |  Val. PPL:   1.223\n",
      " এবং পর ##যে ##াজ ##ন করে কে ##ান ##ও ব ##যা ##পার\n",
      "Epoch  107 Duration =  94.12883305700052\n",
      "\tTrain Loss: 0.425 | Train PPL:   1.530\n",
      "\t Val. Loss: 0.191 |  Val. PPL:   1.211\n",
      " পর ##যে ##াজ ##ন করে হবে না । \n",
      "Epoch  108 Duration =  93.98224796200157\n",
      "\tTrain Loss: 0.426 | Train PPL:   1.531\n",
      "\t Val. Loss: 0.193 |  Val. PPL:   1.213\n",
      " ৩ ) আসার কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  109 Duration =  94.09181960599926\n",
      "\tTrain Loss: 0.426 | Train PPL:   1.531\n",
      "\t Val. Loss: 0.203 |  Val. PPL:   1.224\n",
      " এবং দলের কাছে [UNK] হবে । \n",
      "Epoch  110 Duration =  94.21987861900016\n",
      "\tTrain Loss: 0.424 | Train PPL:   1.527\n",
      "\t Val. Loss: 0.201 |  Val. PPL:   1.222\n",
      " পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  111 Duration =  94.8847271600007\n",
      "\tTrain Loss: 0.422 | Train PPL:   1.526\n",
      "\t Val. Loss: 0.192 |  Val. PPL:   1.211\n",
      " পর ##যে ##াজ ##ন , বিবেচনা করে ##ে কে ##ান ##ও কাজ\n",
      "Epoch  112 Duration =  94.60311421900042\n",
      "\tTrain Loss: 0.420 | Train PPL:   1.522\n",
      "\t Val. Loss: 0.197 |  Val. PPL:   1.217\n",
      " পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  113 Duration =  94.28948272699927\n",
      "\tTrain Loss: 0.418 | Train PPL:   1.518\n",
      "\t Val. Loss: 0.196 |  Val. PPL:   1.217\n",
      " এবং বির ##দ ##ধে কড ##া হবে না । \n",
      "Epoch  114 Duration =  94.08687619800003\n",
      "\tTrain Loss: 0.414 | Train PPL:   1.513\n",
      "\t Val. Loss: 0.193 |  Val. PPL:   1.213\n",
      " পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  115 Duration =  94.11862825699973\n",
      "\tTrain Loss: 0.412 | Train PPL:   1.510\n",
      "\t Val. Loss: 0.198 |  Val. PPL:   1.219\n",
      " এবং এর বির ##দ ##ধে পর ##যে ##াজ ##ন হবে না ।\n",
      "Epoch  116 Duration =  94.11621711400039\n",
      "\tTrain Loss: 0.412 | Train PPL:   1.509\n",
      "\t Val. Loss: 0.204 |  Val. PPL:   1.226\n",
      " পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  117 Duration =  94.21596878799937\n",
      "\tTrain Loss: 0.412 | Train PPL:   1.510\n",
      "\t Val. Loss: 0.204 |  Val. PPL:   1.226\n",
      " এবং মে ##যে ##দের অস ##বিধ ##া হবে না । \n",
      "Epoch  118 Duration =  95.07808014300099\n",
      "\tTrain Loss: 0.409 | Train PPL:   1.505\n",
      "\t Val. Loss: 0.203 |  Val. PPL:   1.226\n",
      " পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  119 Duration =  94.89586380100081\n",
      "\tTrain Loss: 0.409 | Train PPL:   1.505\n",
      "\t Val. Loss: 0.199 |  Val. PPL:   1.220\n",
      " পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  120 Duration =  94.97867589199996\n",
      "\tTrain Loss: 0.409 | Train PPL:   1.505\n",
      "\t Val. Loss: 0.191 |  Val. PPL:   1.211\n",
      " ’ ’ তব বির ##দ ##ধে কড ##া হবে না । \n",
      "Epoch  121 Duration =  94.8589204079999\n",
      "\tTrain Loss: 0.407 | Train PPL:   1.503\n",
      "\t Val. Loss: 0.192 |  Val. PPL:   1.211\n",
      " [UNK] করে পানি পাচ ##ছে না । \n",
      "Epoch  122 Duration =  94.85707808500047\n",
      "\tTrain Loss: 0.406 | Train PPL:   1.500\n",
      "\t Val. Loss: 0.202 |  Val. PPL:   1.223\n",
      " এবং এই [UNK] পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  123 Duration =  94.67244552699958\n",
      "\tTrain Loss: 0.404 | Train PPL:   1.498\n",
      "\t Val. Loss: 0.195 |  Val. PPL:   1.215\n",
      " করম ##শ করে এই পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  124 Duration =  94.7193308269998\n",
      "\tTrain Loss: 0.402 | Train PPL:   1.495\n",
      "\t Val. Loss: 0.198 |  Val. PPL:   1.219\n",
      " ওখানে মজ ##বত করে উপ ##য ##কত থাকবে না । \n",
      "Epoch  125 Duration =  94.881364982999\n",
      "\tTrain Loss: 0.400 | Train PPL:   1.492\n",
      "\t Val. Loss: 0.200 |  Val. PPL:   1.222\n",
      " সেখানে [UNK] করে ##ান ##ও কাজ হবে না । \n",
      "Epoch  126 Duration =  94.36516971700075\n",
      "\tTrain Loss: 0.401 | Train PPL:   1.493\n",
      "\t Val. Loss: 0.201 |  Val. PPL:   1.223\n",
      " ’ ’ পক ##ষ থেকে কে ##ান ##ও স ##থ ##গি ##ত\n",
      "Epoch  127 Duration =  94.20805688499968\n",
      "\tTrain Loss: 0.400 | Train PPL:   1.491\n",
      "\t Val. Loss: 0.183 |  Val. PPL:   1.201\n",
      " এবং এই দ ##টে ##া পর ##যে ##াজ ##ন হবে না ।\n",
      "Epoch  128 Duration =  94.04248784899937\n",
      "\tTrain Loss: 0.402 | Train PPL:   1.494\n",
      "\t Val. Loss: 0.199 |  Val. PPL:   1.220\n",
      " এবং এই পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  129 Duration =  94.01411795499916\n",
      "\tTrain Loss: 0.398 | Train PPL:   1.489\n",
      "\t Val. Loss: 0.193 |  Val. PPL:   1.213\n",
      " ’ ’ টি পাচ ##দি করে রাখা হবে না । \n",
      "Epoch  130 Duration =  94.07395118100067\n",
      "\tTrain Loss: 0.398 | Train PPL:   1.488\n",
      "\t Val. Loss: 0.189 |  Val. PPL:   1.208\n",
      " ’ ’ টি কার ##য ##কর করে পর ##যে ##াজ ##ন হবে\n",
      "Epoch  131 Duration =  95.06157487900055\n",
      "\tTrain Loss: 0.395 | Train PPL:   1.485\n",
      "\t Val. Loss: 0.187 |  Val. PPL:   1.206\n",
      " এবং কে ##ান ##ও ম ##ঙ ##গল ##ক হয না । \n",
      "Epoch  132 Duration =  94.20620299899929\n",
      "\tTrain Loss: 0.394 | Train PPL:   1.483\n",
      "\t Val. Loss: 0.180 |  Val. PPL:   1.197\n",
      " ’ করে কে ##ান ##ও স ##জ ##ঞ ##রা হবে না ।\n",
      "Epoch  133 Duration =  94.23290259799978\n",
      "\tTrain Loss: 0.394 | Train PPL:   1.482\n",
      "\t Val. Loss: 0.189 |  Val. PPL:   1.208\n",
      " এবং পর ##যে ##াজ ##ন হবে না । \n",
      "Epoch  134 Duration =  94.65133066899944\n",
      "\tTrain Loss: 0.394 | Train PPL:   1.483\n",
      "\t Val. Loss: 0.192 |  Val. PPL:   1.211\n",
      " তে ##ামা ##কে এই করে দেও ##যা হবে না । \n",
      "Epoch  135 Duration =  94.53109964699979\n",
      "\tTrain Loss: 0.393 | Train PPL:   1.482\n",
      "\t Val. Loss: 0.184 |  Val. PPL:   1.202\n",
      " এবং এই দ ##টে ##ান ##টি হবে না । \n",
      "Epoch  136 Duration =  94.2730014280005\n",
      "\tTrain Loss: 0.391 | Train PPL:   1.479\n",
      "\t Val. Loss: 0.187 |  Val. PPL:   1.206\n",
      " এবং পাচ ##দি করে কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  137 Duration =  94.11856183899909\n",
      "\tTrain Loss: 0.389 | Train PPL:   1.476\n",
      "\t Val. Loss: 0.181 |  Val. PPL:   1.199\n",
      " কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  138 Duration =  94.07181241000035\n",
      "\tTrain Loss: 0.389 | Train PPL:   1.476\n",
      "\t Val. Loss: 0.186 |  Val. PPL:   1.205\n",
      " ’ করে বলেন , ‘ ‘ দ ##টি করে কে ##ান ##ও\n",
      "Epoch  139 Duration =  94.11964545699993\n",
      "\tTrain Loss: 0.387 | Train PPL:   1.473\n",
      "\t Val. Loss: 0.191 |  Val. PPL:   1.211\n",
      " এবং এই দ ##টে ##া করে পর ##যে ##াজ ##ন নেই ।\n",
      "Epoch  140 Duration =  94.01768791500035\n",
      "\tTrain Loss: 0.388 | Train PPL:   1.474\n",
      "\t Val. Loss: 0.189 |  Val. PPL:   1.208\n",
      " এবং ’ এরপর কে ##ান ##ও ম ##ঙ ##গল দেও ##যা হবে\n",
      "Epoch  141 Duration =  93.99791843300045\n",
      "\tTrain Loss: 0.386 | Train PPL:   1.471\n",
      "\t Val. Loss: 0.178 |  Val. PPL:   1.194\n",
      " পর ##যে ##াজ ##ন করে এই ম ##ঞ ##চ করবেন না ।\n",
      "Epoch  142 Duration =  93.97094593200018\n",
      "\tTrain Loss: 0.384 | Train PPL:   1.468\n",
      "\t Val. Loss: 0.171 |  Val. PPL:   1.186\n",
      " ’ ’ টি অভিয ##ে ##াগ মানতে নারাজ । \n",
      "Epoch  143 Duration =  93.90463998900123\n",
      "\tTrain Loss: 0.381 | Train PPL:   1.464\n",
      "\t Val. Loss: 0.185 |  Val. PPL:   1.203\n",
      " এবং এই করে পাচ ##ছি না । \n",
      "Epoch  144 Duration =  93.92480985600014\n",
      "\tTrain Loss: 0.379 | Train PPL:   1.460\n",
      "\t Val. Loss: 0.180 |  Val. PPL:   1.197\n",
      " এবং এই দ ##টে ##া দল বিবেচনা করে কে ##ান ##ও ব\n",
      "Epoch  145 Duration =  94.0456973829987\n",
      "\tTrain Loss: 0.381 | Train PPL:   1.464\n",
      "\t Val. Loss: 0.169 |  Val. PPL:   1.184\n",
      " এবং এই দ ##টে ##া দল মানতে হবে না । \n",
      "Epoch  146 Duration =  94.17443410599844\n",
      "\tTrain Loss: 0.383 | Train PPL:   1.467\n",
      "\t Val. Loss: 0.172 |  Val. PPL:   1.188\n",
      " এবং এই করে দ ##টে ##া কার ##য ##করী নেই । \n",
      "Epoch  147 Duration =  93.95681270000023\n",
      "\tTrain Loss: 0.381 | Train PPL:   1.464\n",
      "\t Val. Loss: 0.180 |  Val. PPL:   1.197\n",
      " ’ ’ পক ##ষ থেকে কে ##ান ##ও স ##জ ##ঞ হবে\n",
      "Epoch  148 Duration =  94.08090166400143\n",
      "\tTrain Loss: 0.379 | Train PPL:   1.461\n",
      "\t Val. Loss: 0.185 |  Val. PPL:   1.204\n",
      " তে ##ামা ##দের বির ##দ ##ধে বিকেল সা ##ডা ##টা [UNK] হবে\n",
      "Epoch  149 Duration =  94.02417834100015\n",
      "\tTrain Loss: 0.378 | Train PPL:   1.459\n",
      "\t Val. Loss: 0.192 |  Val. PPL:   1.212\n",
      " ’ ’ টি করে পাচ ##ছেন না । \n",
      "Epoch  150 Duration =  94.00297741000031\n",
      "\tTrain Loss: 0.376 | Train PPL:   1.457\n",
      "\t Val. Loss: 0.175 |  Val. PPL:   1.191\n",
      " ’ ’ অপ ##েক ##ষা করে মানতে হবে না । \n",
      "Epoch  151 Duration =  94.01795423899966\n",
      "\tTrain Loss: 0.379 | Train PPL:   1.460\n",
      "\t Val. Loss: 0.181 |  Val. PPL:   1.198\n",
      " ৩ ##টি অভি ##জ ##ঞ ##তা হবে না । \n",
      "Epoch  152 Duration =  94.09470084599889\n",
      "\tTrain Loss: 0.377 | Train PPL:   1.458\n",
      "\t Val. Loss: 0.172 |  Val. PPL:   1.187\n",
      " ৩ ##ি শাস ##তির করে এই ম ##ঙ ##গল ##ও হবে না\n",
      "Epoch  153 Duration =  94.08757778700055\n",
      "\tTrain Loss: 0.378 | Train PPL:   1.459\n",
      "\t Val. Loss: 0.171 |  Val. PPL:   1.186\n",
      " কে ##ান ##ও পাচ ##ছে না । \n",
      "Epoch  154 Duration =  94.02935775900005\n",
      "\tTrain Loss: 0.375 | Train PPL:   1.455\n",
      "\t Val. Loss: 0.171 |  Val. PPL:   1.187\n",
      " কে ##ান ##ও পদক ##ষে ##প করে নে ##যা হবে না ।\n",
      "Epoch  155 Duration =  93.98087623399988\n",
      "\tTrain Loss: 0.374 | Train PPL:   1.453\n",
      "\t Val. Loss: 0.175 |  Val. PPL:   1.191\n",
      " কে ##ান ##ও করে জল ##সব ##য হবে না । \n",
      "Epoch  156 Duration =  93.9967802730007\n",
      "\tTrain Loss: 0.372 | Train PPL:   1.451\n",
      "\t Val. Loss: 0.166 |  Val. PPL:   1.181\n",
      " কে ##ান ##ও স ##থ ##গি ##ত করে না । \n",
      "Epoch  157 Duration =  93.9997459369988\n",
      "\tTrain Loss: 0.371 | Train PPL:   1.449\n",
      "\t Val. Loss: 0.169 |  Val. PPL:   1.184\n",
      " কে ##ান ##ও স ##টে ##ারে ##ই তারা হবে না । \n",
      "Epoch  158 Duration =  93.94955390399991\n",
      "\tTrain Loss: 0.367 | Train PPL:   1.443\n",
      "\t Val. Loss: 0.169 |  Val. PPL:   1.184\n",
      " কে ##ান ##ও স ##যে ##াগ নেই । \n",
      "Epoch  159 Duration =  94.1635813110006\n",
      "\tTrain Loss: 0.368 | Train PPL:   1.445\n",
      "\t Val. Loss: 0.176 |  Val. PPL:   1.192\n",
      " ’ ’ কিনত কে ##ান ##ও স ##ষ ##ঠ হবে না ।\n",
      "Epoch  160 Duration =  94.06527351799923\n",
      "\tTrain Loss: 0.368 | Train PPL:   1.445\n",
      "\t Val. Loss: 0.181 |  Val. PPL:   1.198\n",
      " দলে কে ##ান ##ও পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  161 Duration =  94.57007546599925\n",
      "\tTrain Loss: 0.366 | Train PPL:   1.442\n",
      "\t Val. Loss: 0.167 |  Val. PPL:   1.182\n",
      " তে ##ামা ##দের কাছে কে ##ান ##ও দে ##যা হবে না ।\n",
      "Epoch  162 Duration =  94.74546803799967\n",
      "\tTrain Loss: 0.366 | Train PPL:   1.442\n",
      "\t Val. Loss: 0.163 |  Val. PPL:   1.177\n",
      " কে ##ান ##ও গর ##ে ##পত ##ার করে হবে না । \n",
      "Epoch  163 Duration =  94.01906024800155\n",
      "\tTrain Loss: 0.361 | Train PPL:   1.435\n",
      "\t Val. Loss: 0.160 |  Val. PPL:   1.173\n",
      " কে ##ান ##ও দিকে , এই করে একট নেই । \n",
      "Epoch  164 Duration =  94.1187800179996\n",
      "\tTrain Loss: 0.361 | Train PPL:   1.434\n",
      "\t Val. Loss: 0.150 |  Val. PPL:   1.162\n",
      " কে ##ান ##ও গর ##ন ##থ ##ক ##য করে না । \n",
      "Epoch  165 Duration =  94.0832937489995\n",
      "\tTrain Loss: 0.361 | Train PPL:   1.435\n",
      "\t Val. Loss: 0.153 |  Val. PPL:   1.165\n",
      " এবং এই দ ##টে ##া কার ##য ##কর করে তলব না ।\n",
      "Epoch  166 Duration =  94.0911305440004\n",
      "\tTrain Loss: 0.361 | Train PPL:   1.435\n",
      "\t Val. Loss: 0.158 |  Val. PPL:   1.171\n",
      " ৩ ) আসার কে ##ান ##ও স ##থ ##গি ##ত নেই ।\n",
      "Epoch  167 Duration =  94.07741244200042\n",
      "\tTrain Loss: 0.360 | Train PPL:   1.434\n",
      "\t Val. Loss: 0.161 |  Val. PPL:   1.175\n",
      " এবং এই দ ##টে ##ান ##দের গর ##হণ করবেন না । \n",
      "Epoch  168 Duration =  94.03904803099977\n",
      "\tTrain Loss: 0.359 | Train PPL:   1.431\n",
      "\t Val. Loss: 0.165 |  Val. PPL:   1.179\n",
      " কে ##ান ##ও দিকে পাচ ##ছেন না । \n",
      "Epoch  169 Duration =  93.98650042100053\n",
      "\tTrain Loss: 0.359 | Train PPL:   1.431\n",
      "\t Val. Loss: 0.170 |  Val. PPL:   1.185\n",
      " কে ##ান ##ও দিকে , সেটা পাচ [UNK] হবে না । \n",
      "Epoch  170 Duration =  94.00431297400064\n",
      "\tTrain Loss: 0.361 | Train PPL:   1.435\n",
      "\t Val. Loss: 0.171 |  Val. PPL:   1.186\n",
      " এবং এই দ ##টে ##া করে আমরা সেটা বিবেচনা করব না ।\n",
      "Epoch  171 Duration =  94.01401110200095\n",
      "\tTrain Loss: 0.362 | Train PPL:   1.436\n",
      "\t Val. Loss: 0.164 |  Val. PPL:   1.179\n",
      " কে ##ান ##ও দিকে করে বিকেল সা ##ডা ##দ ##ব ##টা পর\n",
      "Epoch  172 Duration =  94.20011422300013\n",
      "\tTrain Loss: 0.359 | Train PPL:   1.432\n",
      "\t Val. Loss: 0.171 |  Val. PPL:   1.186\n",
      " ’ ’ এরপর তে ##ামা ##দের বির ##দ ##ধে কে ##ান ##ও\n",
      "Epoch  173 Duration =  94.03751863800062\n",
      "\tTrain Loss: 0.357 | Train PPL:   1.428\n",
      "\t Val. Loss: 0.164 |  Val. PPL:   1.178\n",
      " ’ ’ পক ##ষে কে ##ান ##ও ম ##ঞ ##জ ##ই হবে\n",
      "Epoch  174 Duration =  94.13283705199865\n",
      "\tTrain Loss: 0.359 | Train PPL:   1.432\n",
      "\t Val. Loss: 0.164 |  Val. PPL:   1.179\n",
      " ’ ’ পক ##ষ থেকে কে ##ান ##ও স ##যে ##াগ পাবেন\n",
      "Epoch  175 Duration =  94.11298575899855\n",
      "\tTrain Loss: 0.360 | Train PPL:   1.434\n",
      "\t Val. Loss: 0.154 |  Val. PPL:   1.166\n",
      " কে ##ান ##ও দিকে মন ##কত হও ##যা উচিত নয । \n",
      "Epoch  176 Duration =  94.03923339299945\n",
      "\tTrain Loss: 0.360 | Train PPL:   1.434\n",
      "\t Val. Loss: 0.156 |  Val. PPL:   1.169\n",
      " এবং পা ##টে ##ান ##দের গর ##ে ##ফত ##ার হবে না ।\n",
      "Epoch  177 Duration =  94.06574536900007\n",
      "\tTrain Loss: 0.361 | Train PPL:   1.434\n",
      "\t Val. Loss: 0.166 |  Val. PPL:   1.181\n",
      " ’ ’ তে ##ামা ##দের বির ##দ ##ধে মামলা থাকবে না ।\n",
      "Epoch  178 Duration =  94.11179703099697\n",
      "\tTrain Loss: 0.359 | Train PPL:   1.431\n",
      "\t Val. Loss: 0.165 |  Val. PPL:   1.179\n",
      " এবং ’ টি করে দেও ##যা হবে না । \n",
      "Epoch  179 Duration =  94.11584402800145\n",
      "\tTrain Loss: 0.359 | Train PPL:   1.432\n",
      "\t Val. Loss: 0.160 |  Val. PPL:   1.173\n",
      " ’ ’ তে ##া রাত ##রে ##র দিকে ##ন নেই । \n",
      "Epoch  180 Duration =  94.04130275699936\n",
      "\tTrain Loss: 0.356 | Train PPL:   1.427\n",
      "\t Val. Loss: 0.164 |  Val. PPL:   1.179\n",
      " এবং এই দ ##ষট ##ি পর ##যে ##াজ ##ন হবে না ।\n",
      "Epoch  181 Duration =  93.90242089100138\n",
      "\tTrain Loss: 0.355 | Train PPL:   1.426\n",
      "\t Val. Loss: 0.164 |  Val. PPL:   1.178\n",
      " এবং এই দ ##টে ##া দল জানাতে হবে না । \n",
      "Epoch  182 Duration =  93.9059851910024\n",
      "\tTrain Loss: 0.355 | Train PPL:   1.426\n",
      "\t Val. Loss: 0.158 |  Val. PPL:   1.171\n",
      " এবং সেই নথি ##ভ ##কত করে রাখা উচিত নয । \n",
      "Epoch  183 Duration =  93.9370525359991\n",
      "\tTrain Loss: 0.354 | Train PPL:   1.425\n",
      "\t Val. Loss: 0.158 |  Val. PPL:   1.171\n",
      " এবং মে ##াট ##রস ##াইক ##েল করে তলব ##ে না । \n",
      "Epoch  184 Duration =  93.97716455699992\n",
      "\tTrain Loss: 0.353 | Train PPL:   1.423\n",
      "\t Val. Loss: 0.160 |  Val. PPL:   1.174\n",
      " এবং মে ##াট ##ে কে ##ান ##ও কাজ হবে না । \n",
      "Epoch  185 Duration =  94.06946822100144\n",
      "\tTrain Loss: 0.353 | Train PPL:   1.423\n",
      "\t Val. Loss: 0.149 |  Val. PPL:   1.160\n",
      " এবং মে ##াট ##ে কে ##ান ##ও স ##টে ##াগ নেই ।\n",
      "Epoch  186 Duration =  94.01217999299843\n",
      "\tTrain Loss: 0.351 | Train PPL:   1.421\n",
      "\t Val. Loss: 0.150 |  Val. PPL:   1.162\n",
      " করম ##ীদের কাছে জল দেও ##যা হবে না । \n",
      "Epoch  187 Duration =  93.94230672900085\n",
      "\tTrain Loss: 0.350 | Train PPL:   1.419\n",
      "\t Val. Loss: 0.141 |  Val. PPL:   1.151\n",
      " ৩ ) এই দ ##ষট ##ি উঠে আসবে না । \n",
      "Epoch  188 Duration =  93.92621254700134\n",
      "\tTrain Loss: 0.350 | Train PPL:   1.419\n",
      "\t Val. Loss: 0.147 |  Val. PPL:   1.158\n",
      " [UNK] করে বিকেল জল ##টা [UNK] দল । \n",
      "Epoch  189 Duration =  93.9755617080009\n",
      "\tTrain Loss: 0.348 | Train PPL:   1.416\n",
      "\t Val. Loss: 0.146 |  Val. PPL:   1.157\n",
      " কে ##ান ##ও দিকে এটা পাচ ##ছে না । \n",
      "Epoch  190 Duration =  93.91912762100037\n",
      "\tTrain Loss: 0.347 | Train PPL:   1.415\n",
      "\t Val. Loss: 0.153 |  Val. PPL:   1.166\n",
      " কে ##ান ##ও পর ##জ ##ঞ ##রা বিকেল পাও ##যা যাবে না\n",
      "Epoch  191 Duration =  94.00046515500071\n",
      "\tTrain Loss: 0.349 | Train PPL:   1.417\n",
      "\t Val. Loss: 0.152 |  Val. PPL:   1.164\n",
      " ৩ ##টি বির ##দ ##ধে বিকেল সা ##ডে এই দিকে ##া পাচ\n",
      "Epoch  192 Duration =  93.75619969500258\n",
      "\tTrain Loss: 0.352 | Train PPL:   1.422\n",
      "\t Val. Loss: 0.154 |  Val. PPL:   1.167\n",
      " দল তে ##া এই পর ##স ##তাব দেও ##যা হবে না ।\n",
      "Epoch  193 Duration =  93.31292697699973\n",
      "\tTrain Loss: 0.351 | Train PPL:   1.420\n",
      "\t Val. Loss: 0.154 |  Val. PPL:   1.167\n",
      " কে ##ান ##ও পাচ ##ছে না । \n",
      "Epoch  194 Duration =  93.39069258300151\n",
      "\tTrain Loss: 0.347 | Train PPL:   1.416\n",
      "\t Val. Loss: 0.143 |  Val. PPL:   1.154\n",
      " কে ##ান ##ও পাচ ##জন করে বিকেল সা ##ডে কে ##ান ##ও\n",
      "Epoch  195 Duration =  93.32394058000136\n",
      "\tTrain Loss: 0.346 | Train PPL:   1.413\n",
      "\t Val. Loss: 0.144 |  Val. PPL:   1.155\n",
      " কে ##ান ##ও গর ##ন ##থ হই ##যা দেও ##যা হবে না\n",
      "Epoch  196 Duration =  93.27143159899788\n",
      "\tTrain Loss: 0.347 | Train PPL:   1.414\n",
      "\t Val. Loss: 0.158 |  Val. PPL:   1.172\n",
      " এবং এই দ ##টে ##া দল পর ##যে ##াজ ##ন হবে না\n",
      "Epoch  197 Duration =  93.3425527670006\n",
      "\tTrain Loss: 0.351 | Train PPL:   1.420\n",
      "\t Val. Loss: 0.149 |  Val. PPL:   1.160\n",
      " উন ##ন ##যন ##ের দিকে তে ##া শাস ##তর ##পদ হবে না\n",
      "Epoch  198 Duration =  93.30403648700303\n",
      "\tTrain Loss: 0.351 | Train PPL:   1.421\n",
      "\t Val. Loss: 0.165 |  Val. PPL:   1.180\n",
      " এবং এই দ ##টে ##া দল পর ##যে ##াজ ##ন হবে না\n",
      "Epoch  199 Duration =  93.31075196399979\n",
      "\tTrain Loss: 0.353 | Train PPL:   1.424\n",
      "\t Val. Loss: 0.161 |  Val. PPL:   1.175\n",
      " কে ##ান ##ও ##রকম করে এই পর ##স ##ঙ ##গে সেটা জে\n",
      "Epoch  200 Duration =  93.22651858300014\n",
      "\tTrain Loss: 0.349 | Train PPL:   1.418\n",
      "\t Val. Loss: 0.144 |  Val. PPL:   1.155\n",
      " এবং কে ##ান ##ও করে বিকেল সা ##ডা ##টা [UNK] হবে না\n",
      "Epoch  201 Duration =  93.25634500799788\n",
      "\tTrain Loss: 0.345 | Train PPL:   1.412\n",
      "\t Val. Loss: 0.137 |  Val. PPL:   1.147\n",
      " এবং দ ##টে ##া করে বিকেল সা ##ডা ফেলে না । \n",
      "Epoch  202 Duration =  93.28918082900054\n",
      "\tTrain Loss: 0.345 | Train PPL:   1.412\n",
      "\t Val. Loss: 0.142 |  Val. PPL:   1.153\n",
      " এবং এই দ ##টে ##া দল । \n",
      "Epoch  203 Duration =  93.28145566599778\n",
      "\tTrain Loss: 0.346 | Train PPL:   1.413\n",
      "\t Val. Loss: 0.143 |  Val. PPL:   1.154\n",
      " ’ ’ মামলা মানতে নারাজ । \n",
      "Epoch  204 Duration =  93.3025824480028\n",
      "\tTrain Loss: 0.347 | Train PPL:   1.415\n",
      "\t Val. Loss: 0.136 |  Val. PPL:   1.146\n",
      " কে ##ান ##ও দিকে ##ন করে দেখ ##ন না । \n",
      "Epoch  205 Duration =  93.29400852100298\n",
      "\tTrain Loss: 0.345 | Train PPL:   1.412\n",
      "\t Val. Loss: 0.140 |  Val. PPL:   1.151\n",
      " দলে কে ##ান ##ও আত ##ম ##হত ##যা হবে না । \n",
      "Epoch  206 Duration =  93.28013842799919\n",
      "\tTrain Loss: 0.342 | Train PPL:   1.408\n",
      "\t Val. Loss: 0.143 |  Val. PPL:   1.153\n",
      " কে ##ান ##ও দিকে দল নিরব ##াচ ##ন করে ##েই । \n",
      "Epoch  207 Duration =  93.31131853699844\n",
      "\tTrain Loss: 0.342 | Train PPL:   1.407\n",
      "\t Val. Loss: 0.140 |  Val. PPL:   1.151\n",
      " এবং কে ##ান ##ও করে এই পর ##যা ##স হবে না ।\n",
      "Epoch  208 Duration =  93.28382363499986\n",
      "\tTrain Loss: 0.344 | Train PPL:   1.411\n",
      "\t Val. Loss: 0.158 |  Val. PPL:   1.171\n",
      " তে ##ামা ##র দ ##ষট ##ি হবে না । \n",
      "Epoch  209 Duration =  93.2810312640031\n",
      "\tTrain Loss: 0.346 | Train PPL:   1.414\n",
      "\t Val. Loss: 0.148 |  Val. PPL:   1.159\n",
      " জল এসে এই ব ##যা ##পারে পর ##কতি ##র দ ##ষট ##ি\n",
      "Epoch  210 Duration =  93.2932017819985\n",
      "\tTrain Loss: 0.345 | Train PPL:   1.412\n",
      "\t Val. Loss: 0.153 |  Val. PPL:   1.165\n",
      " দল করার কে ##ান ##ও পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  211 Duration =  93.30788830600068\n",
      "\tTrain Loss: 0.344 | Train PPL:   1.411\n",
      "\t Val. Loss: 0.154 |  Val. PPL:   1.166\n",
      " এবং এই ##পের বির ##দ ##ধে বিকেল সা ##দ ##টা [UNK] করে\n",
      "Epoch  212 Duration =  93.29187715200169\n",
      "\tTrain Loss: 0.341 | Train PPL:   1.407\n",
      "\t Val. Loss: 0.152 |  Val. PPL:   1.164\n",
      " এবং বিকেল সা ##ডে ম ##ঞ ##চ খল ##ে দেও ##যা হবে\n",
      "Epoch  213 Duration =  93.2418486730021\n",
      "\tTrain Loss: 0.341 | Train PPL:   1.406\n",
      "\t Val. Loss: 0.150 |  Val. PPL:   1.162\n",
      " এবং দ ##ষট ##ান ##ত করে এই ব ##যা ##পার ##টা দেখাতে\n",
      "Epoch  214 Duration =  93.3112139779987\n",
      "\tTrain Loss: 0.339 | Train PPL:   1.404\n",
      "\t Val. Loss: 0.150 |  Val. PPL:   1.162\n",
      " এটা তে ##ামা ##কে বিকেল সা ##ডে দে ##যা হবে না ।\n",
      "Epoch  215 Duration =  93.88107882700206\n",
      "\tTrain Loss: 0.340 | Train PPL:   1.405\n",
      "\t Val. Loss: 0.148 |  Val. PPL:   1.159\n",
      " এবং জ ##যে ##াতি ##ষ ##বিজ ##ঞা ##ন পর ##যা ##পত হও\n",
      "Epoch  216 Duration =  93.2522040570002\n",
      "\tTrain Loss: 0.344 | Train PPL:   1.411\n",
      "\t Val. Loss: 0.162 |  Val. PPL:   1.176\n",
      " বিকেল সা ##ডে এই ##পের বিকেল সা ##ডে কে ##ান ##ও পর\n",
      "Epoch  217 Duration =  93.34638538299987\n",
      "\tTrain Loss: 0.341 | Train PPL:   1.406\n",
      "\t Val. Loss: 0.147 |  Val. PPL:   1.159\n",
      " এবং বিকেল সা ##টা [UNK] দিকে কে ##ান ##ও পর ##যে ##াজ\n",
      "Epoch  218 Duration =  93.30777966700043\n",
      "\tTrain Loss: 0.339 | Train PPL:   1.404\n",
      "\t Val. Loss: 0.135 |  Val. PPL:   1.145\n",
      " করম ##শ ##স ##চি হও ##যা উচিত নয । \n",
      "Epoch  219 Duration =  93.2796423769978\n",
      "\tTrain Loss: 0.342 | Train PPL:   1.407\n",
      "\t Val. Loss: 0.146 |  Val. PPL:   1.158\n",
      " কে ##ান ##ও গর ##ন ##থ হও ##যা হবে না । \n",
      "Epoch  220 Duration =  93.33991315800085\n",
      "\tTrain Loss: 0.339 | Train PPL:   1.403\n",
      "\t Val. Loss: 0.136 |  Val. PPL:   1.146\n",
      " এবং বিকেল সা ##ডে ম ##যন ##ি , সেটা নেই । \n",
      "Epoch  221 Duration =  93.28254630800075\n",
      "\tTrain Loss: 0.337 | Train PPL:   1.401\n",
      "\t Val. Loss: 0.139 |  Val. PPL:   1.149\n",
      " কে ##ান ##ও নির ##দ ##তত [UNK] দল হতে হবে না ।\n",
      "Epoch  222 Duration =  93.24347803899946\n",
      "\tTrain Loss: 0.335 | Train PPL:   1.399\n",
      "\t Val. Loss: 0.144 |  Val. PPL:   1.155\n",
      " কে ##ান ##ও করে বিকেল সা ##দ ##টা পর ##চ ##ণ ##ড\n",
      "Epoch  223 Duration =  93.33633844400174\n",
      "\tTrain Loss: 0.335 | Train PPL:   1.398\n",
      "\t Val. Loss: 0.151 |  Val. PPL:   1.163\n",
      " এতে করে বিকেল সা ##টা হর ##দ ##টা দল । \n",
      "Epoch  224 Duration =  93.33175279300121\n",
      "\tTrain Loss: 0.336 | Train PPL:   1.399\n",
      "\t Val. Loss: 0.134 |  Val. PPL:   1.144\n",
      " এবং করে পাচ ##জন , এই ##পের নির ##দেশ দেও ##যা হবে\n",
      "Epoch  225 Duration =  93.30484838399934\n",
      "\tTrain Loss: 0.338 | Train PPL:   1.402\n",
      "\t Val. Loss: 0.142 |  Val. PPL:   1.153\n",
      " কে ##ান ##ও করে পাচ ##জন শাস ##তর ##ে চলবে না ।\n",
      "Epoch  226 Duration =  93.33670447500117\n",
      "\tTrain Loss: 0.333 | Train PPL:   1.396\n",
      "\t Val. Loss: 0.138 |  Val. PPL:   1.148\n",
      " এবং এই দ ##টে ##া করে পর ##যে ##াজ ##ন নেই ।\n",
      "Epoch  227 Duration =  93.29372548800166\n",
      "\tTrain Loss: 0.333 | Train PPL:   1.396\n",
      "\t Val. Loss: 0.130 |  Val. PPL:   1.139\n",
      " ’ ’ আত ##ম ##হত ##যা করার কে ##ান ##ও ম ##ঙ\n",
      "Epoch  228 Duration =  93.27005643899975\n",
      "\tTrain Loss: 0.334 | Train PPL:   1.396\n",
      "\t Val. Loss: 0.121 |  Val. PPL:   1.129\n",
      " কে ##ান ##ও করে একট খে ##জ ##র হও ##যা হবে না\n",
      "Epoch  229 Duration =  93.30841755000074\n",
      "\tTrain Loss: 0.334 | Train PPL:   1.397\n",
      "\t Val. Loss: 0.126 |  Val. PPL:   1.134\n",
      " এবং এ নি ##যে ##জ পর ##কাশ করার কে ##ান ##ও বিকেল\n",
      "Epoch  230 Duration =  93.35286386400185\n",
      "\tTrain Loss: 0.335 | Train PPL:   1.398\n",
      "\t Val. Loss: 0.138 |  Val. PPL:   1.148\n",
      " এবং কে ##ান ##ও নির ##যা ##তন ##ের করে নিন না ।\n",
      "Epoch  231 Duration =  93.29292788999737\n",
      "\tTrain Loss: 0.333 | Train PPL:   1.396\n",
      "\t Val. Loss: 0.139 |  Val. PPL:   1.149\n",
      " এটার ( [UNK] ) বির ##দ ##ধে পাচ ##ছে না । \n",
      "Epoch  232 Duration =  93.29248737300077\n",
      "\tTrain Loss: 0.336 | Train PPL:   1.399\n",
      "\t Val. Loss: 0.147 |  Val. PPL:   1.158\n",
      " এটা মানতে নারাজ । \n",
      "Epoch  233 Duration =  93.2984613669978\n",
      "\tTrain Loss: 0.335 | Train PPL:   1.397\n",
      "\t Val. Loss: 0.152 |  Val. PPL:   1.164\n",
      " এটা মানতে নারাজ । \n",
      "Epoch  234 Duration =  93.28836013899854\n",
      "\tTrain Loss: 0.333 | Train PPL:   1.395\n",
      "\t Val. Loss: 0.140 |  Val. PPL:   1.150\n",
      " এতে করে বিকেল সা ##ডে এই পর ##যে ##াজ ##ন নেই ।\n",
      "Epoch  235 Duration =  93.31436106000183\n",
      "\tTrain Loss: 0.336 | Train PPL:   1.400\n",
      "\t Val. Loss: 0.145 |  Val. PPL:   1.156\n",
      " তারা বিকেল সা ##ডে ##ান ##ও ম ##ঞ ##চ ও ##র ।\n",
      "Epoch  236 Duration =  93.30256773300061\n",
      "\tTrain Loss: 0.338 | Train PPL:   1.402\n",
      "\t Val. Loss: 0.142 |  Val. PPL:   1.152\n",
      " এটার ( [UNK] ) হবে না । \n",
      "Epoch  237 Duration =  93.24514438400001\n",
      "\tTrain Loss: 0.336 | Train PPL:   1.399\n",
      "\t Val. Loss: 0.136 |  Val. PPL:   1.146\n",
      " ’ ’ এখনও পর ##যন ##ত ##াজ ##ন নেই । \n",
      "Epoch  238 Duration =  93.26437245800116\n",
      "\tTrain Loss: 0.333 | Train PPL:   1.395\n",
      "\t Val. Loss: 0.131 |  Val. PPL:   1.140\n",
      " এটার ( [UNK] ) নির ##যা ##তন ##ের করে নেই । \n",
      "Epoch  239 Duration =  93.30521349700211\n",
      "\tTrain Loss: 0.332 | Train PPL:   1.393\n",
      "\t Val. Loss: 0.140 |  Val. PPL:   1.150\n",
      " এতে করে বিকেল সা ##ডে হে ##ান ##ও পর ##যে ##াজ ##ন\n",
      "Epoch  240 Duration =  93.29322146500272\n",
      "\tTrain Loss: 0.331 | Train PPL:   1.393\n",
      "\t Val. Loss: 0.126 |  Val. PPL:   1.134\n",
      " এবং কে ##ান ##ও বিকেল সা ##ডে ম ##ঞ ##চ নেই ।\n",
      "Epoch  241 Duration =  93.26176848700197\n",
      "\tTrain Loss: 0.328 | Train PPL:   1.388\n",
      "\t Val. Loss: 0.127 |  Val. PPL:   1.136\n",
      " এবং জ ##যে ##াতি ##রিক ##ত বিষ ##য ##টা । \n",
      "Epoch  242 Duration =  93.32789472700097\n",
      "\tTrain Loss: 0.330 | Train PPL:   1.391\n",
      "\t Val. Loss: 0.131 |  Val. PPL:   1.140\n",
      " এতে ##ে ##ান ##ও লক ##ষ ##যে ##পের ব ##যা ##পার হতে\n",
      "Epoch  243 Duration =  93.32640181799798\n",
      "\tTrain Loss: 0.332 | Train PPL:   1.394\n",
      "\t Val. Loss: 0.136 |  Val. PPL:   1.145\n",
      " এতে করে বিকেল সা ##ডে কে ##ান ##ও পর ##যে ##াজ ##ন\n",
      "Epoch  244 Duration =  93.27612716300064\n",
      "\tTrain Loss: 0.332 | Train PPL:   1.394\n",
      "\t Val. Loss: 0.138 |  Val. PPL:   1.148\n",
      " এতে বিকেল কে ##ান ##ও পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  245 Duration =  93.29369730799954\n",
      "\tTrain Loss: 0.332 | Train PPL:   1.394\n",
      "\t Val. Loss: 0.140 |  Val. PPL:   1.150\n",
      " এতে করে বিকেল সা ##ডে এই পর ##যে ##াজ ##ন নেই ।\n",
      "Epoch  246 Duration =  93.29150769300031\n",
      "\tTrain Loss: 0.331 | Train PPL:   1.392\n",
      "\t Val. Loss: 0.133 |  Val. PPL:   1.142\n",
      " এতে করে পাচ ##ছে না । \n",
      "Epoch  247 Duration =  93.29498871399846\n",
      "\tTrain Loss: 0.333 | Train PPL:   1.396\n",
      "\t Val. Loss: 0.143 |  Val. PPL:   1.154\n",
      " এতে পর ##যে ##াজ ##ন নেই । \n",
      "Epoch  248 Duration =  93.26792524899793\n",
      "\tTrain Loss: 0.331 | Train PPL:   1.392\n",
      "\t Val. Loss: 0.140 |  Val. PPL:   1.150\n",
      " এতে করে বিকেল সা ##ডে পাচ ##টা পর ##যে ##াজ ##ন নেই\n",
      "Epoch  249 Duration =  93.33127184700061\n",
      "\tTrain Loss: 0.332 | Train PPL:   1.394\n",
      "\t Val. Loss: 0.144 |  Val. PPL:   1.155\n",
      " কে ##ান ##ও গর ##ে ##ফত ##ার হবে না । \n",
      "Epoch  250 Duration =  93.28556024999853\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 250\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "#     gc.collect()\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. PPL: {math.exp(val_loss):7.3f}')\n",
    "    print(translate(transformer, \"There will be no interruption.\"))\n",
    "    print(\"Epoch \",epoch ,\"Duration = \",end_time-start_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46e0fc7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T00:36:41.896971Z",
     "iopub.status.busy": "2024-03-03T00:36:41.896667Z",
     "iopub.status.idle": "2024-03-03T00:36:42.356144Z",
     "shell.execute_reply": "2024-03-03T00:36:42.355154Z"
    },
    "papermill": {
     "duration": 0.494948,
     "end_time": "2024-03-03T00:36:42.358564",
     "exception": false,
     "start_time": "2024-03-03T00:36:41.863616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('filename.pkl', 'wb') as f:\n",
    "    pickle.dump(transformer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f35fa436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T00:36:42.425476Z",
     "iopub.status.busy": "2024-03-03T00:36:42.425163Z",
     "iopub.status.idle": "2024-03-03T00:36:42.462850Z",
     "shell.execute_reply": "2024-03-03T00:36:42.461968Z"
    },
    "papermill": {
     "duration": 0.0728,
     "end_time": "2024-03-03T00:36:42.464710",
     "exception": false,
     "start_time": "2024-03-03T00:36:42.391910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " খাবারের ##ও বা ##ডাব ##াড ##ি ।\n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer,\"food\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1272055,
     "sourceId": 2119948,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23930.992386,
   "end_time": "2024-03-03T00:36:44.669519",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-02T17:57:53.677133",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0370eb21f31c447ab1aac9ed39746023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a6f1bd9d3465450887a831e208d13a5f",
       "placeholder": "​",
       "style": "IPY_MODEL_4146204d3fc944018ab2e2b8c76805ea",
       "value": " 491/491 [00:00&lt;00:00, 41.1kB/s]"
      }
     },
     "3a33d04892ff47f6bd50f209a1b42496": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f0bbceca7d90482ebccb2564ebfd82ae",
        "IPY_MODEL_3ff3b389db2f41ef9598e78e9a97f26d",
        "IPY_MODEL_d4868d8898614a878eb1467c8b3eed0e"
       ],
       "layout": "IPY_MODEL_5fe0e3cf5da7425ea7c38b098cf38c32"
      }
     },
     "3ff3b389db2f41ef9598e78e9a97f26d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b51d47ba6a6643009a251d1b8d667032",
       "max": 2237676.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c0b77b73c3eb47d6b74bcd24ae98c54e",
       "value": 2237676.0
      }
     },
     "407ae5ee19c54c5c8ac06a1cd15a0da2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4146204d3fc944018ab2e2b8c76805ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "468defe252994236883f83c470ff32b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4f43d8a9f9b94cbaa031971869eeb70a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "50c9857fd7f948e8831ecc50b0ca15fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_acd897db13c8479cbb982a05e672188f",
       "placeholder": "​",
       "style": "IPY_MODEL_468defe252994236883f83c470ff32b5",
       "value": "config.json: 100%"
      }
     },
     "5fe0e3cf5da7425ea7c38b098cf38c32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63620093d3c54b74937f5d5ca6346e2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "728dc5f4b7964b8fbb8d17af51fbd160": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_407ae5ee19c54c5c8ac06a1cd15a0da2",
       "max": 491.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cb96f0311c6042f88ab937963e12b982",
       "value": 491.0
      }
     },
     "797d771814c84a3a821703eab1f8d47b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0be2309f6c04f189a9669fc7261d09e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6f1bd9d3465450887a831e208d13a5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acd897db13c8479cbb982a05e672188f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b51d47ba6a6643009a251d1b8d667032": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0b77b73c3eb47d6b74bcd24ae98c54e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cb96f0311c6042f88ab937963e12b982": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d4868d8898614a878eb1467c8b3eed0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_797d771814c84a3a821703eab1f8d47b",
       "placeholder": "​",
       "style": "IPY_MODEL_63620093d3c54b74937f5d5ca6346e2b",
       "value": " 2.24M/2.24M [00:00&lt;00:00, 2.25MB/s]"
      }
     },
     "d59ee10e565e4a8381ab27d6f5e02a74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_50c9857fd7f948e8831ecc50b0ca15fa",
        "IPY_MODEL_728dc5f4b7964b8fbb8d17af51fbd160",
        "IPY_MODEL_0370eb21f31c447ab1aac9ed39746023"
       ],
       "layout": "IPY_MODEL_a0be2309f6c04f189a9669fc7261d09e"
      }
     },
     "ebe57d36475b46fd80a321afeab93984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0bbceca7d90482ebccb2564ebfd82ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ebe57d36475b46fd80a321afeab93984",
       "placeholder": "​",
       "style": "IPY_MODEL_4f43d8a9f9b94cbaa031971869eeb70a",
       "value": "vocab.txt: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
